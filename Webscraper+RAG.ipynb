{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6003651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "import getpass\n",
    "os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter API key for Mistral: \")\n",
    "api = os.environ[\"MISTRAL_API_KEY\"]\n",
    "from langchain_mistralai import ChatMistralAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d900a73d51a7489080d36457fceef2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1650e1542e674d43968adc4d227ecd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d29041686d64fa4965a44cc4cada11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ed88799da049b685d3790378a8d20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0019cdedfe04f79b09c1cebc66e723c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff75db5d2f5454fa8bd692491cb1bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7a232b40e0455d90febafefe86e2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae36c08b68d48c682c5f6cf4d769527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4410d9247f4510b86fca14fa84bb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92eb1ac787a44eeb20a6a4a22bd672f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05322c58ad52464c94a9300d9ac3b93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tavily_top_links(query, api_key, num_links=5):\n",
    "    tavily_endpoint = 'https://api.tavily.com/search' \n",
    "    payload = {'query': query, 'max_results': num_links, 'api_key': api_key}\n",
    "    resp = requests.post(tavily_endpoint, json=payload)\n",
    "    data = resp.json()\n",
    "    return [item['url'] for item in data.get('results', [])[:num_links]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c278282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks(chunks):\n",
    "    return model.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(all_chunks):\n",
    "    embeddings = embed_chunks(all_chunks)\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, all_chunks, embeddings_index, embedder, N=5):\n",
    "    query_vec = embedder.encode([query])\n",
    "    D, I = embeddings_index.search(np.array(query_vec), k=N)\n",
    "    return [all_chunks[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_chunk(url, chunk_size=500):\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=5)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "        chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8403e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_rag_agent(query, context_chunks):\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    prompt = f\"Based only on the following:\\n{context}\\nAnswer this question: {query}\"\n",
    "    llm = ChatMistralAI(model=\"mistral-small-latest\", api_key=api)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers using ONLY the provided web context.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    return llm.invoke(messages)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_scrape_rag(query, tavily_key):\n",
    "    urls = tavily_top_links(query, tavily_key, num_links=5)\n",
    "    all_chunks = []\n",
    "    for url in urls:\n",
    "        all_chunks.extend(scrape_and_chunk(url))\n",
    "    index, _ = build_faiss_index(all_chunks)\n",
    "    relevant_chunks = retrieve_relevant_chunks(query, all_chunks, index, model, k=5)\n",
    "    answer = ask_rag_agent(query, relevant_chunks)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048353dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-year-of-quantum-from-concept-to-reality-in-2025: HTTPSConnectionPool(host='www.mckinsey.com', port=443): Read timed out. (read timeout=5)\n",
      "content=\"Based on the provided context, the latest advances in quantum computing include:\\n\\n1. **Real-world implementations**: Quantum computing is moving beyond theoretical exploration and entering a phase of practical innovation and application. This includes advancements in hardware, algorithms, and integration with other technologies, impacting fields such as artificial intelligence, pharmaceuticals, and telecommunications.\\n\\n2. **IBM's advancements**: IBM has achieved significant milestones and innovations that redefine the capabilities and applications of quantum computing. Their recent unveiling of new quantum processors, such as Heron and Condor, demonstrates the growing practicality of quantum technologies.\\n\\n3. **Quantum connectivity**: Advances in linking quantum processors can amplify computing power, pushing the boundaries of what quantum computers can achieve.\\n\\n4. **Challenges to traditional encryption**: The advancements in quantum capabilities pose significant challenges to traditional encryption methods and cybersecurity.\\n\\n5. **Technical and ethical challenges**: As quantum computing progresses, it brings forth new technical and ethical challenges that need to be addressed.\\n\\nThese advances highlight the rapid evolution of quantum computing and its increasing utility in solving complex problems.\" additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 570, 'total_tokens': 791, 'completion_tokens': 221}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop'} id='run--0765074e-9ecb-437f-8aaf-d94817fda658-0' usage_metadata={'input_tokens': 570, 'output_tokens': 221, 'total_tokens': 791}\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What are the latest advances in the field of LLMs?\"\n",
    "tavily_key = getpass.getpass(\"Enter tavily key:\")\n",
    "result = search_scrape_rag(user_query, tavily_key= tavily_key)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
